import os
import time
import json
import re
import random
import datetime
from random import randint
from collections import Counter
from huggingface_hub import InferenceClient

max_rounds = 10  # Maximale Runden als Fallback
HF_TOKEN = os.environ.get("HF_TOKEN")

client = InferenceClient(provider="together", api_key=HF_TOKEN)
json_path = "/home/neuendankbe92700/stutter-abcd/conversation_data.json"

metadata = {
    "timestamp": datetime.datetime.now().isoformat(),
    "model_used": "openai/gpt-oss-120b",
    "parameters": {
        "stutter_probability": 0.15,
        "max_rounds": max_rounds,
        "temperature": 0.7,
        "max_tokens": 120
    },
    "stutter_statistics": {
        "total_words": 0,
        "stuttered_words": 0,
        "stutter_rate": 0.0,
        "stutter_types": Counter(),
    },
    "conversation_metrics": {
        "total_messages": 0,
        "response_times": [],
        "conversation_duration": 0
    },
    "conversation_data": []
}

system_manager = """
Du bist ein KI-Dialog-Manager in einer BÃ¤ckerei.
Du bekommst den bisherigen GesprÃ¤chsverlauf und den aktuellen Zustand (state).
Entscheide, was der nÃ¤chste Zustand sein soll.
Antworte IMMER als JSON im Format:
{"next_state": "...", "agreement": false, "reason": "..."}.
Erlaubte States: greeting, details, offer, agreement, closing.
Wenn der Kunde etwas gekauft oder zugestimmt hat, setze agreement = true.
Wenn das GesprÃ¤ch natÃ¼rlich beendet werden kann, setze next_state = "closing".
"""

customer_messages = [
    {"role": "system", "content": (
        "Du bist ein Kunde in einer BÃ¤ckerei. BegrÃ¼ÃŸe den BÃ¤cker freundlich "
        "und frag nach Brot. Sprich locker, natÃ¼rlich, maximal zwei vollstÃ¤ndigen SÃ¤tze."
    )}
]

baker_messages = [
    {"role": "system", "content": (
        "Du bist ein BÃ¤cker. Sei freundlich, locker und menschlich. "
        "Sprich kurz in zwei vollstÃ¤ndigen SÃ¤tzen, ohne Listen, Sterne, Klammern, Tabellen, AbkÃ¼rzungen, Gedankenstriche oder Emojis."
    )}
]

evaluator_messages = [
    {"role": "system", "content": (
        "Du bist ein neutraler Evaluator. Beurteile die Antwort des Kunden und BÃ¤ckers."
        "Beurteile den Context Relevance Score, Task Success Rate und Role Concistency Score. "
        "Bewerte auf einer Skala von 1 bis 10, wobei 10 die beste Bewertung ist. "
        "Antworte IMMER nur mit JSON: {context_relevance, task_success, role_consistency}."
        "BegrÃ¼nde kurz warum die Bewertungen so sind."
        "Bewerte beide Rollen einzelnd."
    )}
]

def evaluate_response(stuttered_ai, fluent_ai):
    evaluate_ai = stuttered_ai.choices[0].message.content.strip()
    evaluate_fluent = fluent_ai.choices[0].message.content.strip()
    completion_evaluator = client.chat.completions.create(
        model="openai/gpt-oss-120b",
        messages=[
            {"role": "system", "content": evaluator_messages[0]["content"]},
            {"role": "user", "content": f"Stotternde Antwort: {evaluate_ai}\nFlÃ¼ssige Antwort: {evaluate_fluent}"}
        ],
    )
    raw = completion_evaluator.choices[0].message.content.strip()
    print("ğŸ“ Evaluator:", raw)
    return None

def get_baker_prompt(state):
    if state == "greeting":
        return "BegrÃ¼ÃŸe den Kunden freundlich und frag, was er mÃ¶chte. Maximal zwei SÃ¤tze."
    elif state == "details":
        return "Reagiere freundlich auf die Bestellung und frag nach Sorte und Menge. Zwei bis drei SÃ¤tze."
    elif state == "offer":
        return "Sag den Preis in einem Satz, bestÃ¤tige, dass das Brot frisch geschnitten werden kann, und frag, ob noch etwas gewÃ¼nscht wird."
    elif state == "agreement":
        return "BestÃ¤tige die Bestellung kurz. Ein kurzer Satz."
    elif state == "closing":
        return "Verabschiede dich freundlich und wÃ¼nsche einen schÃ¶nen Tag. Ein Satz genÃ¼gt."
    else:
        return "Beende das GesprÃ¤ch hÃ¶flich in einem Satz."

def add_stutter(text, stutter_prob=0.15):
    words = text.split()
    stuttered_text = []
    for word in words:
        clean = re.sub(r"[^\w]", "", word)
        metadata["stutter_statistics"]["total_words"] += 1
        if len(clean) > 2 and random.random() < stutter_prob:
            t = random.choice(["repeat", "partial", "block"])
            metadata["stutter_statistics"]["stutter_types"][t] += 1
            metadata["stutter_statistics"]["stuttered_words"] += 1
            if t == "repeat":
                r = clean[:random.randint(1, min(2, len(clean)//2))]
                stuttered_text.append(f"{r}-{r}-{word}")
            elif t == "partial":
                p = clean[:random.randint(1, 2)]
                stuttered_text.append(f"{p}... {word}")
            else:
                stuttered_text.append(f"... {word}")
        else:
            stuttered_text.append(word)
    return " ".join(stuttered_text)

def manager_decide(state, history):
    try:
        convo_text = "\n".join([f"{m['speaker']}: {m['clean_message']}" for m in history[-6:]])
        user_input = f"Aktueller State: {state}\nGesprÃ¤ch:\n{convo_text}"
        response = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=[
                {"role": "system", "content": system_manager},
                {"role": "user", "content": user_input},
            ],
        )
        raw = response.choices[0].message.content
        match = re.search(r"\{.*\}", raw, re.DOTALL)
        if match:
            return json.loads(match.group())
        return {"next_state": state, "agreement": False, "reason": "Parsing-Fallback"}
    except Exception as e:
        print(f"âš ï¸ Manager-Fehler: {e}")
        return {"next_state": state, "agreement": False, "reason": "Exception-Fallback"}

def save_conversation_data(metadata, path):
    try:
        data = []
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
        data.append(metadata)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"Fehler beim Speichern: {e}")
        return False

# ==========================
# ğŸ”¹ Haupt-Dialog
# ==========================
state = "greeting"
conversation_start = time.time()
round_num = 0
conversation_active = True
closing_round_completed = False  # ğŸ”¹ NEU: Tracken ob Closing-Runde durchgefÃ¼hrt wurde

while conversation_active and round_num < max_rounds:
    round_num += 1
    print(f"\n=== Runde {round_num} | Aktueller State: {state} ===")

    baker_messages[0]["content"] = "Du bist ein BÃ¤cker. " + get_baker_prompt(state)

    # Kunde antwortet
    try:
        round_start = time.time()
        completion_customer = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=customer_messages
        )
        answer_customer = completion_customer.choices[0].message.content.strip()
        stuttered = add_stutter(answer_customer)
        print("ğŸ§â€â™‚ï¸ Kunde:", stuttered)

        duration = time.time() - round_start
        metadata["conversation_data"].append({
            "round": round_num,
            "speaker": "kunde",
            "message": stuttered,
            "clean_message": answer_customer,
            "response_time": round(duration, 2)
        })
        metadata["conversation_metrics"]["response_times"].append(duration)

        baker_messages.append({"role": "user", "content": answer_customer})
        customer_messages.append({"role": "assistant", "content": answer_customer})

    except Exception as e:
        print(f"Fehler bei Kunden-Antwort: {e}")
        continue

    # BÃ¤cker antwortet
    try:
        round_start = time.time()
        completion_baker = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=baker_messages
        )
        answer_baker = completion_baker.choices[0].message.content.strip()
        print("ğŸ‘¨â€ğŸ³ BÃ¤cker:", answer_baker)

        duration = time.time() - round_start
        metadata["conversation_data"].append({
            "round": round_num,
            "speaker": "baecker",
            "message": answer_baker,
            "clean_message": answer_baker,
            "response_time": round(duration, 2)
        })
        metadata["conversation_metrics"]["response_times"].append(duration)

        customer_messages.append({"role": "user", "content": answer_baker})
        baker_messages.append({"role": "assistant", "content": answer_baker})

    except Exception as e:
        print(f"Fehler bei BÃ¤cker-Antwort: {e}")
        continue

    try:
        print("Evaluator: ")
        evaluation_result = evaluate_response(completion_customer, completion_baker)
    except Exception as e:
        print(f"Fehler bei Evaluator: {e}")

    # Manager entscheidet Ã¼ber nÃ¤chsten State
    decision = manager_decide(state, metadata["conversation_data"])
    print("ğŸ¤– Manager:", decision)

    state = decision.get("next_state", state)
    
    # ğŸ”¹ VERBESSERTE LOGIK: Closing-Runde muss komplett durchgefÃ¼hrt werden
    if state == "closing" and not closing_round_completed:
        print("ğŸ¯ Closing-State erreicht - fÃ¼hre Verabschiedung durch")
        # Lasse noch eine Runde fÃ¼r die Verabschiedung laufen
        closing_round_completed = True
    elif state == "closing" and closing_round_completed:
        print("âœ… Closing-Runde abgeschlossen - beende GesprÃ¤ch")
        conversation_active = False
    elif decision.get("agreement", False):
        print("âœ… Agreement erreicht - wechsle zu Closing")
        state = "closing"

# ğŸ”¹ SICHERSTELLEN, dass Daten gespeichert werden
metadata["conversation_metrics"]["total_messages"] = len(metadata["conversation_data"])
metadata["conversation_metrics"]["conversation_duration"] = round(time.time() - conversation_start, 2)
metadata["conversation_metrics"]["total_rounds"] = round_num
if metadata["stutter_statistics"]["total_words"] > 0:
    metadata["stutter_statistics"]["stutter_rate"] = round(
        metadata["stutter_statistics"]["stuttered_words"] / metadata["stutter_statistics"]["total_words"] * 100, 2
    )
metadata["stutter_statistics"]["stutter_types"] = dict(metadata["stutter_statistics"]["stutter_types"])

# ğŸ”¹ VERBESSERTES SPEICHERN mit Fehlerbehandlung
max_retries = 3
for attempt in range(max_retries):
    if save_conversation_data(metadata, json_path):
        print(f"âœ… Daten gespeichert in: {json_path}")
        break
    else:
        print(f"âŒ Versuch {attempt + 1}/{max_retries} fehlgeschlagen")
        if attempt < max_retries - 1:
            time.sleep(1)  # Warte eine Sekunde vor erneutem Versuch
else:
    print(f"âŒ Alle Speicherversuche fehlgeschlagen fÃ¼r: {json_path}")

print("\n=== KONVERSATION BEENDET ===")
print(f"ğŸ“Š Runden: {round_num}")
print(f"ğŸ’¬ Nachrichten: {metadata['conversation_metrics']['total_messages']}")
print(f"ğŸ—£ï¸  Stotter-Rate: {metadata['stutter_statistics']['stutter_rate']}%")
print(f"â±ï¸  Dauer: {metadata['conversation_metrics']['conversation_duration']}s")
print(f"ğŸ“ˆ Stotter-Typen: {metadata['stutter_statistics']['stutter_types']}")
print(f"ğŸ”š Beendet durch: {'Closing-State' if closing_round_completed else 'Maximale Runden'}")